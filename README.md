# Machine Learning Course

## Challenge

Learn the foundations of machine learning.

## Actions

The following concepts were studied:

* **linear regression**: training set, features, target variable, hypothesis, learning algorithm, parameters, cost function, optimisation problem, gradient descent, learning rate, batch gradient descent
* **multivariate linear regression**: feature scaling, mean normalisation, choosing learning rate, normal equation
* **logistic regression**: classification, logistic function, sigmoid function, decision boundary, nonlinear decision boundaries, cost function, optimisation algorithms, multiclass classification, one-vs-all
* **regularisation**: overfitting, regularisation parameter, regularised linear regression, regularised logistic regression
* **neural networks**: computer vision, sigmoid activation function, layers, bias, forward propagation, nonlinear classification, back propagation algorithm, random initialisation
* **model selection**: training / validation / test sets, diagnosing bias and variance, cross validation error, regularisation, learning curves, high bias, high variance, error analysis, precision, recall, F1 score
* **support vector machines**: SVM hypotesis, large margin classifier,  kernels, similarity, Gaussian kernel, linear kernel, polynomial kernel, 
* **unsupervised learning**: clustering, K-means
* **principal component analysis**: dimensionality reduction, data compression, data visualisation, covariance matrix sigma, eigenvectors of sigma, reconstruction from compressed representation, number pf principal components, learning speedup
* **k-means clustering**: cluster index, cluster centroid, random initialisation, elbow method
* **anomaly detection**: density estimation, normal vs anomalous, fraud detection, manufacturing, monitoring working parameters, Gaussian distribution, features, error analysis
* **recommender system**s: content based recommendations, collaborative filtering, low rank matrix factorisation, mean normalisation, 
* **large scale machine learning**: stochastic gradient descent, mini-batch gradient descent, online learning, map-reduce and data parallelism, 



## Results

The tool of choice for this course was Matlab / Octave; each machine learning algorithm was coded in a project.

As a proof of accomplishment, the following certificate was issued: [https://www.coursera.org/account/accomplishments/certificate/WLHZZ6TPVVM2](https://www.coursera.org/account/accomplishments/certificate/WLHZZ6TPVVM2)â€‹.

